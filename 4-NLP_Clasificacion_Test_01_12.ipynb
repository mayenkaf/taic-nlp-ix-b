{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Clasificacion-Test-01-12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zys1BGq3mwf"
      },
      "source": [
        "#  Clasificador de Noticias Falsas\n",
        "\n",
        "Codigo de Estudiante:....\n",
        "\n",
        "Apellidos y Nombres:.....\n",
        "\n",
        "Fecha de Presentación:...\n",
        "\n",
        "---\n",
        "@author: mfch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXfzYnfz3ugX"
      },
      "source": [
        "## Test 03\n",
        "\n",
        "**Instrucciones**\n",
        "1. Importe **CountVectorizer** de *sklearn.feature_extraction.text* y **train_test_split** de *sklearn.model_selection*.\n",
        "2. Cree una Serie **y** para usarla como etiqueta asignando el atributo **.label** de *df* a *y*.\n",
        "3. Use **df[\"text\"]** (como características) y **y** (etiquetas), para crear los dataset de entrenamiento y prueba usando **train_test_split()**, use **test_size = 0.33** y **random_state = 53**.\n",
        "4. Cree un objeto *CountVectorizer* llamado **count_vectorizer**. Asegurese de especificar **stop_words=\"english\"* para remover estas palabras.\n",
        "5. Entrene y transforme los datos de entrenamiento **X_train** usando el método *.fit_transform()* del objeto *CountVectorizer*. Haga lo mismo con **X_test**, solo que debe usar el método *.transform()*.\n",
        "6. Imprima las primeras 10 caracteristicas de *count_vectorizer* usando el método **.get_feature_names()**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zmvls7hW3jRw"
      },
      "source": [
        "import pandas as pd\n",
        "# Import `fake_or_real_news.csv`\n",
        "df = pd.read_csv(\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/fake_or_real_news.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7HQyFOQK6WA"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOpkqA3KNQLO"
      },
      "source": [
        "# Import the necessary modules\n",
        "____\n",
        "____\n",
        "\n",
        "# Print the head of df\n",
        "print(df.head())\n",
        "\n",
        "# Create a series to store the labels: y\n",
        "y = ____\n",
        "\n",
        "# Create training and test sets\n",
        "X_train, X_test, y_train, y_test = ____\n",
        "\n",
        "# Initialize a CountVectorizer object: count_vectorizer\n",
        "count_vectorizer = ____\n",
        "\n",
        "# Transform the training data using only the 'text' column values: count_train \n",
        "count_train = ____\n",
        "\n",
        "# Transform the test data using only the 'text' column values: count_test \n",
        "count_test = ____\n",
        "\n",
        "# Print the first 10 features of the count_vectorizer\n",
        "print(____[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qwcXXtSP_A9"
      },
      "source": [
        "## Test 04\n",
        "\n",
        "**Instrucciones**\n",
        "1. Importe **TfidfVectorizer** desde *sklearn.feature_extraction.text*.\n",
        "2. Cree un objeto *TfidfVectorizer* llamado **tfidf_vectorizer**. Especifique los argumentos **stop_words=\"english\"** y **max_df=0.7**.\n",
        "4. Entrene y transforme los datos de entrenamiento.\n",
        "5. Transforme los datos de prueba.\n",
        "6. Imprima las 10 primeras caracteristicas del vector **tfidf_vectorizer**.\n",
        "7. Imprima los primeros 5 vectores *tfidf* de los datos de entrenamientousando *slicing* en el atributo **.A** (o array) de **tfidf_train**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbMEQHRqQWI3"
      },
      "source": [
        "# Import TfidfVectorizer\n",
        "____\n",
        "\n",
        "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
        "tfidf_vectorizer = ____\n",
        "\n",
        "# Transform the training data: tfidf_train \n",
        "tfidf_train = ____\n",
        "\n",
        "# Transform the test data: tfidf_test \n",
        "tfidf_test = ____\n",
        "\n",
        "# Print the first 10 features\n",
        "print(____[:10])\n",
        "\n",
        "# Print the first 5 vectors of the tfidf training data\n",
        "print(____[:5])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRlTCpscT5Z1"
      },
      "source": [
        "## Test 05\n",
        "\n",
        "**Instrucciones**\n",
        "1. Cree los DataFrames **count_df** y **tfidf_df** usando pd.DataFrame() y especificando los valores como primer argumento y las columnas (o features) como segundo argumento. Los valores pueden ser accedidos usando el atributo **.A** de *count_train* y *tfidf_train* respectivamente; las columnas pueden ser accedidas usando los metodos **.get_feature_names()** de *count_vectorizer* y *tfidf_vectorizer*.\n",
        "2. Imprima el encabeazdo de cada DataFrame (.head()) para observar su estructura.\n",
        "3. Pruebe si los nombres de las columnas son los mismos para cada DataFrame al crear un nuevo objeto llamado **difference** para ver la diferencias entre las columnas que **count_df** tiene de **tfidf_df**. Las columnas pueden ser accedidas usando el atributo **.columns** de un DataFrame. Sustraiga el conjunto de clomunas de **tfidf_df.columns** desde el conjunto de **count_df.columns**.\n",
        "4. Pruebe si los dos DataFrames son equivalentes usando el método **.equals()**  en *count_df* con *tfidf_df* como argumentos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZgz5wQ7VotF"
      },
      "source": [
        "# Create the CountVectorizer DataFrame: count_df\n",
        "count_df = ____(____, columns=____)\n",
        "\n",
        "# Create the TfidfVectorizer DataFrame: tfidf_df\n",
        "tfidf_df = ____\n",
        "\n",
        "# Print the head of count_df\n",
        "print(count_df.head())\n",
        "\n",
        "# Print the head of tfidf_df\n",
        "print(tfidf_df.head())\n",
        "\n",
        "# Calculate the difference in columns: difference\n",
        "difference = set(____) - set(____)\n",
        "print(difference)\n",
        "\n",
        "# Check whether the DataFrames are equal\n",
        "print(____)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lvZODyCXm_H"
      },
      "source": [
        "## Test 07\n",
        "**Instrucciones**\n",
        "1. Importe el modulo **metrics** de *sklearn* y **MultinomialNB** de *sklearn.naive_bayes*.\n",
        "2. Instancie un clasificador *MultinomialNB* llamado **nb_classifier**.\n",
        "3. Entrene el clasificador con los datos de entrenamiento.\n",
        "4. Calcule las etiquetas de prediccion para los datos de prueba.\n",
        "5. Calcule e imprima la exactitud del clasificador.\n",
        "6. Calcule la matriz de confusión. Para facilitar la lectura, especifique el argumento **labels=['FAKE', 'REAL']**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ytV0R2hYfdc"
      },
      "source": [
        "# Import the necessary modules\n",
        "____\n",
        "____\n",
        "\n",
        "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
        "nb_classifier = ____\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "____\n",
        "\n",
        "# Create the predicted tags: pred\n",
        "pred = ____\n",
        "\n",
        "# Calculate the accuracy score: score\n",
        "score = ____\n",
        "print(score)\n",
        "\n",
        "# Calculate the confusion matrix: cm\n",
        "cm = ____\n",
        "print(cm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDYcRT2Daboz"
      },
      "source": [
        "## Test 08\n",
        "**Instrucciones**\n",
        "1. Instancie un clasificador **MultinomialNB** llamado **nb_classifier**.\n",
        "2. Entrene el clasificador con los datos de entrenamiento.\n",
        "3. Calcule las etiquetas de predicción con los datos de prueba.\n",
        "4. Calcule e imprima la exactitud del clasificador.\n",
        "5. Clacule la matriz de confusión, especifique el argumento **labels=['FAKE', 'REAL']** para que sea fácil de leer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrmSGKcVa-72"
      },
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Create a Multinomial Naive Bayes classifier: nb_classifier\n",
        "nb_classifier = ____\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "____\n",
        "\n",
        "# Create the predicted tags: pred\n",
        "pred = ____\n",
        "\n",
        "# Calculate the accuracy score: score\n",
        "score = ____\n",
        "print(score)\n",
        "\n",
        "# Calculate the confusion matrix: cm\n",
        "cm = ____\n",
        "print(cm)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qi8NMUdgb95R"
      },
      "source": [
        "## Test 10\n",
        "**Instrucciones**\n",
        "1. Cree una lista de alphas usando **np.arange()**. Los valores deben ir desde  0 a 1 con steps de 0.1.\n",
        "2. Cree una funcion **train_and_predict()** que tome como argumento: alpha. La función debe: Instanciar un clasificador *MultinomialNB* con **alpha=alpha**, entrenelo con los datos de entrenamiento, calcule las predicciones con los datos de prueba, calcule la exactitud.\n",
        "3. Usando un **for**, imprima *alpha*, *exactitud y un salto de linea entre ellos. Use la función *train_and_predict()* para calcular la puntuación. ¿Cambia la puntuacion con los valores de alphas? ¿Cuál es el mejor alpha?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGM7IMWCdsl2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create the list of alphas: alphas\n",
        "alphas = ____\n",
        "\n",
        "# Define train_and_predict()\n",
        "def ____(____):\n",
        "    # Instantiate the classifier: nb_classifier\n",
        "    nb_classifier = ____\n",
        "    # Fit to the training data\n",
        "    ____\n",
        "    # Predict the labels: pred\n",
        "    pred = ____\n",
        "    # Compute accuracy: score\n",
        "    score = ____\n",
        "    return score\n",
        "\n",
        "# Iterate over the alphas and print the corresponding score\n",
        "for alpha in alphas:\n",
        "    print('Alpha: ', alpha)\n",
        "    print('Score: ', ____)\n",
        "    print()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji0V5RsJzg1q"
      },
      "source": [
        "##Test 11\n",
        "\n",
        "**Instrucciones**\n",
        "1. Guarde las clases de etiquetas como **class_labels** accediendo con el atributo **.classes_ attribute** de *nb_classifier*.\n",
        "2. Extraiga las caracteristicas usando el método **.get_feature_names()** de **tfidf_vectorizer**.\n",
        "3. Cree un array comprimido de los coeficientes del clasificador con los nombres de las y ordenelos por los coeficientes. Para hacer esto, use primero **zip()** con los argumentos **nb_classifier.coef_[0]** y **feature_names**. Luego use **sorted()** en este.\n",
        "4. Imprima las 20 caracteristicas ponderadas más altas de *class_labels* e imprima las caracteristicas ponderadas  más bajas de la segunda etiqueta de las etiquetas de clase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF-FTRkH1Q7I"
      },
      "source": [
        "# Get the class labels: class_labels\n",
        "class_labels = ____\n",
        "\n",
        "# Extract the features: feature_names\n",
        "feature_names = ____\n",
        "\n",
        "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
        "feat_with_weights = ____(____(____, ____))\n",
        "\n",
        "# Print the first class label and the top 20 feat_with_weights entries\n",
        "print(class_labels[0], feat_with_weights[:20])\n",
        "\n",
        "# Print the second class label and the bottom 20 feat_with_weights entries\n",
        "print(class_labels[1], feat_with_weights[-20:])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WdBPL1FAL5c"
      },
      "source": [
        "##Test 12\n",
        "**Comparando otro clasificador con Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdFgZH1YASuU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}